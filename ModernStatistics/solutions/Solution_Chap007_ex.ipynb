{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60abddc3",
   "metadata": {},
   "source": [
    "# Exercise Chapter 7 \n",
    "Modern Statistics: A Computer Based Approach with Python<br>\n",
    "by Ron Kenett, Shelemyahu Zacks, Peter Gedeck\n",
    "\n",
    "Publisher: Springer International Publishing; 1st edition (September 15, 2022) <br>\n",
    "ISBN-13: 978-3031075650\n",
    "\n",
    "(c) 2022 Ron Kenett, Shelemyahu Zacks, Peter Gedeck\n",
    "\n",
    "The code needs to be executed in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OUTDATED_IGNORE'] = '1'\n",
    "import warnings\n",
    "from outdated import OutdatedPackageWarning\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=OutdatedPackageWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45068d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import mistat\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Uncomment the following if xgboost crashes\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e6fc1",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f69737",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = mistat.load_data('SENSORS.csv')\n",
    "predictors = [c for c in sensors.columns if c.startswith('sensor')]\n",
    "outcome = 'testResult'\n",
    "X = sensors[predictors]\n",
    "y = sensors[outcome]\n",
    "\n",
    "# Train the model\n",
    "clf = DecisionTreeClassifier(ccp_alpha=0.012, random_state=0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ConfusionMatrixDisplay.from_estimator(clf, X, y, ax=ax, cmap=plt.cm.Blues)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24bc785",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c7eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the status information into numerical labels\n",
    "outcome = 'status'\n",
    "y = sensors[outcome].replace({'Pass': 1, 'Fail': 0})\n",
    "\n",
    "# Train the model\n",
    "xgb = XGBClassifier(objective='binary:logistic', subsample=.63,\n",
    "                    eval_metric='logloss', use_label_encoder=False,\n",
    "                    seed=1)\n",
    "xgb.fit(X, y)\n",
    "\n",
    "# actual in rows / predicted in columns\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(y, xgb.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp = pd.DataFrame({\n",
    "  'importance': xgb.feature_importances_,\n",
    "  }, index=predictors)\n",
    "var_imp = var_imp.sort_values(by='importance', ascending=False)\n",
    "var_imp['order'] = range(1, len(var_imp) + 1)\n",
    "print(var_imp.head(10))\n",
    "var_imp.loc[var_imp.index.isin(['sensor18', 'sensor07', 'sensor21'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27910890",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8675f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sensors['status']\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier(ccp_alpha=0.012, random_state=0)\n",
    "model.fit(X, y)\n",
    "\n",
    "# actual in rows / predicted in columns\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(y, model.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e1fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp = pd.DataFrame({\n",
    "  'importance': model.feature_importances_,\n",
    "  }, index=predictors)\n",
    "var_imp = var_imp.sort_values(by='importance', ascending=False)\n",
    "var_imp['order'] = range(1, len(var_imp) + 1)\n",
    "print(var_imp.head(10))\n",
    "var_imp.loc[var_imp.index.isin(['sensor18', 'sensor07', 'sensor21'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2e0464",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert outcome values from strings into numerical labels\n",
    "# use le.inverse_transform to convert the predictions to strings\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(sensors['status'])\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y,\n",
    "  test_size=0.4, random_state=2)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(ccp_alpha=0.012, random_state=0)\n",
    "dt_model.fit(train_X, train_y)\n",
    "\n",
    "xgb_model = XGBClassifier(objective='binary:logistic', subsample=.63,\n",
    "                  eval_metric='logloss', use_label_encoder=False,\n",
    "                  seed=1)\n",
    "xgb_model.fit(train_X, train_y)\n",
    "\n",
    "rf_model = RandomForestClassifier(ccp_alpha=0.014, random_state=0)\n",
    "rf_model.fit(train_X, train_y)\n",
    "\n",
    "print('Decision tree model')\n",
    "print(f'Accuracy {accuracy_score(valid_y, dt_model.predict(valid_X)):.3f}')\n",
    "print(confusion_matrix(valid_y, dt_model.predict(valid_X)))\n",
    "\n",
    "print('Gradient boosting model')\n",
    "print(f'Accuracy {accuracy_score(valid_y, xgb_model.predict(valid_X)):.3f}')\n",
    "print(confusion_matrix(valid_y, xgb_model.predict(valid_X)))\n",
    "\n",
    "print('Random forest model')\n",
    "print(f'Accuracy {accuracy_score(valid_y, rf_model.predict(valid_X)):.3f}')\n",
    "print(confusion_matrix(valid_y, rf_model.predict(valid_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada6f5f2",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a0d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(ccp_alpha=0.012)\n",
    "\n",
    "random_valid_acc = []\n",
    "random_train_acc = []\n",
    "org_valid_acc = []\n",
    "org_train_acc = []\n",
    "for _ in range(100):\n",
    "  train_X, valid_X, train_y, valid_y = train_test_split(X, y,\n",
    "    test_size=0.4)\n",
    "  dt_model.fit(train_X, train_y)\n",
    "  org_train_acc.append(accuracy_score(train_y, dt_model.predict(train_X)))\n",
    "  org_valid_acc.append(accuracy_score(valid_y, dt_model.predict(valid_X)))\n",
    "\n",
    "  random_y = random.sample(list(train_y), len(train_y))\n",
    "  dt_model.fit(train_X, random_y)\n",
    "  random_train_acc.append(accuracy_score(random_y, dt_model.predict(train_X)))\n",
    "  random_valid_acc.append(accuracy_score(valid_y, dt_model.predict(valid_X)))\n",
    "\n",
    "ax = pd.Series(random_valid_acc).plot.density(color='C0')\n",
    "pd.Series(random_train_acc).plot.density(color='C0', linestyle='--',\n",
    "                                      ax=ax)\n",
    "pd.Series(org_valid_acc).plot.density(color='C1', ax=ax)\n",
    "pd.Series(org_train_acc).plot.hist(color='C1', linestyle='--',\n",
    "                                   ax=ax)\n",
    "ax.set_ylim(0, 40)\n",
    "ax.set_xlim(0, 1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab120c3",
   "metadata": {},
   "source": [
    "# Exercise 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ebbc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "distTower = mistat.load_data('DISTILLATION-TOWER.csv')\n",
    "predictors = ['Temp1', 'Temp2', 'Temp3', 'Temp4', 'Temp5', 'Temp6',\n",
    "              'Temp7', 'Temp8', 'Temp9', 'Temp10', 'Temp11', 'Temp12']\n",
    "outcome = 'VapourPressure'\n",
    "Xr = distTower[predictors]\n",
    "yr = distTower[outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, valid_X, train_y, valid_y = train_test_split(Xr, yr,\n",
    "  test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5efe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to analyze tree depth vs alpha\n",
    "model = DecisionTreeRegressor(random_state=0)\n",
    "path = model.cost_complexity_pruning_path(Xr, yr)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "mse = []\n",
    "mse_train = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    model = DecisionTreeRegressor(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    model.fit(train_X, train_y)\n",
    "    mse.append(mean_squared_error(valid_y, model.predict(valid_X)))\n",
    "    mse_train.append(mean_squared_error(train_y, model.predict(train_X)))\n",
    "ccp_alpha = ccp_alphas[np.argmin(mse)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a20b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(ccp_alphas, mse_train, drawstyle='steps-post', color='grey')\n",
    "ax.plot(ccp_alphas, mse, marker='o', drawstyle=\"steps-post\",\n",
    "        color='black')\n",
    "ax.set_xlabel(\"Cost-complexity parameter (ccp_alpha)\")\n",
    "ax.set_ylabel(\"MSE of test set\")\n",
    "ax.set_xscale('log')\n",
    "ax.axvline(ccp_alpha, color='grey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbf1d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtreeviz.trees import dtreeviz\n",
    "\n",
    "def viz2pdf(viz, pdfFile):\n",
    "  from svglib.svglib import svg2rlg\n",
    "  from reportlab.graphics import renderPDF\n",
    "  from tempfile import NamedTemporaryFile\n",
    "  with NamedTemporaryFile(mode='w+', suffix='.svg') as f:\n",
    "    f.write(viz.svg())\n",
    "    f.flush()\n",
    "    f.seek(0)\n",
    "    drawing = svg2rlg(f.name)\n",
    "    renderPDF.drawToFile(drawing, pdfFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43aab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore user warning thrown here\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b36440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dtreeviz methods requires the classifier to be trained with a numerical\n",
    "# representation of the classes\n",
    "# Train the model\n",
    "model = DecisionTreeRegressor(ccp_alpha=ccp_alpha, random_state=0)\n",
    "model.fit(Xr, yr)\n",
    "\n",
    "viz = dtreeviz(model, Xr, yr,\n",
    "               target_name=outcome,\n",
    "               feature_names=Xr.columns)\n",
    "viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbbf585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore user warning thrown here\n",
    "warnings.filterwarnings('default', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f8b262",
   "metadata": {},
   "source": [
    "# Exercise 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ea2e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sensors['status']\n",
    "\n",
    "results = []\n",
    "for strategy in 'uniform', 'quantile', 'kmeans':\n",
    "  for n_bins in range(2, 11):\n",
    "    kbinsDiscretizer = KBinsDiscretizer(encode='ordinal',\n",
    "      strategy=strategy, n_bins=n_bins)\n",
    "    X_binned = kbinsDiscretizer.fit_transform(X)\n",
    "    nb_model = MultinomialNB()\n",
    "    nb_model.fit(X_binned, y)\n",
    "    results.append({'strategy': strategy, 'n_bins': n_bins,\n",
    "       'accuracy': accuracy_score(y, nb_model.predict(X_binned))})\n",
    "results = pd.DataFrame(results)\n",
    "fig, ax = plt.subplots()\n",
    "for key, group in results.groupby('strategy'):\n",
    "  group.plot(x='n_bins', y='accuracy', label=key, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282e75f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbinsDiscretizer = KBinsDiscretizer(encode='ordinal',\n",
    "  strategy='quantile', n_bins=2)\n",
    "X_binned = kbinsDiscretizer.fit_transform(X)\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_binned, y)\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(y, nb_model.predict(X_binned)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9bc2b6",
   "metadata": {},
   "source": [
    "# Exercise 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b68ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mistat import plot_dendrogram\n",
    "\n",
    "food = mistat.load_data('FOOD.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "model = AgglomerativeClustering(n_clusters=10, compute_distances=True)\n",
    "\n",
    "X = scaler.fit_transform(food)\n",
    "model = model.fit(X)\n",
    "fig, ax = plt.subplots()\n",
    "plot_dendrogram(model, ax=ax)\n",
    "ax.set_title('Dendrogram')\n",
    "ax.get_xaxis().set_ticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb768ef",
   "metadata": {},
   "source": [
    "# Exercise 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4813e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "food = mistat.load_data('FOOD.csv')\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(food)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=2)\n",
    "\n",
    "for linkage, ax in zip(['ward', 'complete', 'average', 'single'], axes.flatten()):\n",
    "  model = AgglomerativeClustering(n_clusters=10, compute_distances=True,\n",
    "    linkage=linkage)\n",
    "  model = model.fit(X)\n",
    "  plot_dendrogram(model, ax=ax)\n",
    "  ax.set_title(linkage)\n",
    "  ax.get_xaxis().set_ticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690b7d8f",
   "metadata": {},
   "source": [
    "# Exercise 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab8aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = mistat.load_data('SENSORS.csv')\n",
    "predictors = [c for c in sensors.columns if c.startswith('sensor')]\n",
    "outcome = 'status'\n",
    "X = sensors[predictors]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "model = KMeans(n_clusters=10, random_state=1).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b6053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "  'status': sensors['status'],\n",
    "  'testResult': sensors['testResult'],\n",
    "  'cluster': model.predict(X),\n",
    "})\n",
    "\n",
    "for status, group in df.groupby('status'):\n",
    "  print(f'Status {status}')\n",
    "  print(group['cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e471faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of clusters by testResult')\n",
    "for cluster, group in df.groupby('cluster'):\n",
    "  print(f'Cluster {cluster}')\n",
    "  print(group['testResult'].value_counts())\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c78098",
   "metadata": {},
   "source": [
    "# Exercise 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6192855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "sensors = mistat.load_data('SENSORS.csv')\n",
    "predictors = [c for c in sensors.columns if c.startswith('sensor')]\n",
    "outcome = 'status'\n",
    "X = sensors[predictors]\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "y = sensors[outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd9d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over increasing number of clusters\n",
    "results = []\n",
    "clf = DecisionTreeClassifier(ccp_alpha=0.012, random_state=0)\n",
    "for n_clusters in range(2, 20):\n",
    "  # fit a model and assign the data to clusters\n",
    "  model = KMeans(n_clusters=n_clusters, random_state=1)\n",
    "  model.fit(X)\n",
    "  Xcluster = model.predict(X)\n",
    "  # to use the cluster number in a classifier, use one-hot encoding\n",
    "  # it's necessary to reshape the vector of cluster numbers into a column vector\n",
    "  Xcluster = OneHotEncoder().fit_transform(Xcluster.reshape(-1, 1))\n",
    "\n",
    "  # create a decision tree model and determine the accuracy\n",
    "  clf.fit(Xcluster, y)\n",
    "  results.append({'n_clusters': n_clusters,\n",
    "                  'accuracy': accuracy_score(y, clf.predict(Xcluster))})\n",
    "ax = pd.DataFrame(results).plot(x='n_clusters', y='accuracy')\n",
    "ax.set_ylim(0.5, 1)\n",
    "plt.show()\n",
    "pd.DataFrame(results).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c97a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "clf = DecisionTreeClassifier(ccp_alpha=0.012, random_state=0)\n",
    "for n_clusters in range(2, 20):\n",
    "  # fit a model and convert data to distances\n",
    "  model = KMeans(n_clusters=n_clusters, random_state=1)\n",
    "  model.fit(X)\n",
    "  Xcluster = model.transform(X)\n",
    "\n",
    "  # create a decision tree model and determine the accuracy\n",
    "  clf.fit(Xcluster, y)\n",
    "  results.append({'n_clusters': n_clusters,\n",
    "                  'accuracy': accuracy_score(y, clf.predict(Xcluster))})\n",
    "ax = pd.DataFrame(results).plot(x='n_clusters', y='accuracy')\n",
    "ax.set_ylim(0.5, 1)\n",
    "plt.show()\n",
    "pd.DataFrame(results).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1efd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "  StandardScaler(),\n",
    "  KMeans(n_clusters=6, random_state=1),\n",
    "  DecisionTreeClassifier(ccp_alpha=0.012, random_state=0)\n",
    ")\n",
    "X = sensors[predictors]\n",
    "y = sensors[outcome]\n",
    "\n",
    "process = pipeline.fit(X, y)\n",
    "print('accuracy', accuracy_score(y, process.predict(X)))\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(y, process.predict(X)))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
